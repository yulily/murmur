---
title: "Stable Diffusion Web UI 試した"
description: "Windows で WSL 使ってみた"
pubDate: "Oct. 8 2023"
heroImage: "/murmur/blog/231008/0.png"
---

やっと触りました  
上の画像は生成したものです、可愛い

### 概要
正直 AIイラストのクオリティ高すぎて数ヶ月?ぐらい描く気を失っていたんですが、
写真やデジタルが現れた時のように、いつか普通になるんだろうなぁと思うとﾝﾝﾝ...触ってみるか...と重い腰を上げ試してみました  
試した際の参考にした記事や手順の整理とかメモしておこうと思います  
細かい手順は参考サイトに記載されてるのでここではあまり触れてないです

ちなみにこのために Windows を新調しました

Windows に直接入れようと思ったんですが、色々うまくいかんとなったのと名だけ聞いた事あって気になっていた WSL で動かすことにしました (割と適当) 

### 流れ
ほとんど[「【Windows＋WSL2】Stable Diffusionをローカル環境に実装」](https://hitori-sekai.com/python/stable-diffusion-web-ui/)の手順に従ったのですが、学習済みモデルは差し替えました

[「【Stable Diffusion】美少女イラスト生成におすすめのモデルデータまとめ40選＋α【実写（フォトリアル）・2.5D・アニメイラスト】」](https://yuuyuublog.org/sdmodels/) を見ていて
[「Pastel-Mix [Stylized Anime Model]」](https://civitai.com/models/5414/pastel-mix-stylized-anime-model) が個人的に好みのタッチだったのでこれを利用

差し替え方は[「【2023年】「Stable Diffusion WebUI」をローカル環境に構築するやり方！低スぺックPC（1660Ti）でもOK！」](https://yuuyuublog.org/stablediffusion_local/) を参考にしています

各種インストールや設定、学習モデルの追加を終えたら webui.sh を実行して webui を起動させます  

あとは txt2img や img2img で prompt 使って色々試す感じになります

試していく中で覚えておいた方が良さそうだなって思ったのがいくつかあったのでメモします

### モデルについて
モデルは大きく分けて 2種類
- 学習モデル
    - checkpoint
        - これが先ほど入れたモデルのことです
        - モデル本体・心臓部と呼ばれているらしい
        - 拡張子は safetensors を選ぶ
            - chkpt は古い形式で悪意のあるスクリプトを混入するリスクがあるらしい
            - chkpt よりわずかに高速になるらしい
        - ファイル名はファイルサイズ抑えたい場合は pruned が付いてるものを選ぶ
    - VAE
        - [「【Stable Diffusion Web UI】VAEの使い方
」](https://soroban.highreso.jp/article/article-043#651d5d6690e0c50795c30b63-e41dfaa0ccccf202e3f43b45) がわかりやすかったです
        - 多分先ほどのモデルだけだとボヤけてるので、[「Pastel-Mix [Stylized Anime Model]」](https://civitai.com/models/5414/pastel-mix-stylized-anime-model) の Guide に記載されてる VAE をダウンロードし対象ディレクトリに格納・設定反映を行いました
            - (これは VAE とか関係ありませんが Guide に推奨の設定値が記載されていたので、それも調整するとクオリティがかなり変わりました)
- 追加学習
    - LoRA など
        - モデルに対して、服や髪特徴を固定して画像生成できるようになるらしい
    - 次回この辺試したい

### ライセンスについて
[【画像生成AI】Stable Diffusion派生モデルを利用・公開するときはライセンスに注意しましょう
](https://note.com/hases0110/n/n69b8a5784750)がわかりやすかったです  
モデルは Hugging Face か Civitai で落とすのが主流のようで、これ以外は公式ではないものが殆どのこと  
ライセンスの見方はサイトによって異なり、今回は生成したのアップして大丈夫か？というのが心配になったので確かめたところ  

>Use the model without crediting the creator

に × が付いてなかったので大丈夫そうと掲載してます  
ただいつでも変更できるらしいので、いきなり×になることもあるらしい  
そのため Hugging Face ならリポジトリ落としておく、Civitai は魚拓取っておくというのが安全策のようです 

### 画像生成の tips 的な
後半に txt2img の prompt 書き方がわかりやすく解説されてました
[「日本一わかりやすいStableDiffusion WebUI AUTOMATIC1111(ローカル版)のインストール方法と基本的な使い方
」](https://youtu.be/8QIJMGW_-LM?t=1164)
覚えとこって思ったやつ
- 左に書いたものほど影響が大きい
- キーワードを「品質、環境、主体、作風」と分類し、品質は一番左にし後は使うモデルによって並び替えながら試すと良さそうだった
- (hoge) で強調できるらしい、1つ括りで 1.1倍、数が増えると ^n となるらしい
    - (hoge:1.5) 直接指定もできるらしい
- 逆に弱くする場合は、[] を使うらしい

あと
[Stable Diffusionでリアル・実写系の画像を生成するための呪文（プロンプト）を解説！
](https://bocek.co.jp/media/exercise/stable-diffusion/6282/) も試してみたら結構ハッキリした絵になった気がします

### 次は
[Stable Diffusionで自分の絵を学習させる時のポイントまとめ
](https://note.com/churin_1116/n/nd89460164952) 辺りを試していきたいなぁ...  

ControlNet は入れたけど使ってなかった...次々回かなぁ

### 作成してみたもの
かわいい!  
<img width="200" src="/murmur/blog/231008/1.png">
<img width="200" src="/murmur/blog/231008/2.png">
<img width="200" src="/murmur/blog/231008/3.png">
